<html>
  <head>
  <title>Highlighted Text and Word Counts</title>
  </head>

  <body>

  <div style= " display: table;  justify-content: center;">
  <h4 style="text-align:center;text-shadow: 0.5px 0.5px;">TP Tool Report</h4>
  <div style="display: flex; flex-direction:row">
      <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
      <h4>Torture Phrases Word Counts:</h4>
      </div>
      <div style="width: 50%; border: 0.7px solid #000c; padding: 5px;">
      <div style='color: #FF0000;'>distinguishing proof: 1</div>
    </div>
    
    </div>
    

    
      
  </div>

  <div style="display: flex; flex-direction: row;">
      <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
      <h4>Self citation </h4>
      </div>
      <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
      
      

     NIL
      </div>
      
  </div>
  <div style="display: flex; flex-direction: row;">
      <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
      <h4>Found in Abstract/Conclusion Section:</h4>
      </div>
      <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
      
      

      NIL
      </div>
  


      
  </div>


  <div style="display: flex; flex-direction: row;">
  <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
  <h4>Unmatched Abbreviations:</h4>
  </div>
  <div style=" width: 50%; border: 0.7px solid #000c; padding: 5px;">
  
  

  <div key="AD">
          AD - 3
        </div><div key="CRM">
          CRM - 1
        </div><div key="TDD">
          TDD - 1
        </div><div key="AWS">
          AWS - 1
        </div>
  
  
  
  
  


  </div>



  
</div>

</div>

  <div style="display:table; margin-top:20px;">
  An Architecture-Based Self-Typing Service For Cloud Native Applications



Jayalakshmi





<h5>Abstract</h5>- In this paper, we present Kubow, a service that automatically adjusts to new circumstances, built on a modular framework for cloud-native applications. To accommodate Kubernetes and Docker containers, the Rainbow self-adaptation framework was upgraded to become Kubow. The article provides an overview of Kubow's architecture, highlights its main design decisions, and walks through a simple example of how to set it up and utilize it. It takes more than just installing software on virtual machines to get apps running in the cloud. Cloud applications need continuous management so that they can 1) adjust their resources to the anticipated demand, and 2) respond to temporary disappointments by duplicating and restarting components to offer resilience on unstable infrastructure. To give programmed and responsive responses to disappointments (wellbeing the board) and changing natural conditions (auto-scaling), ceaseless administration persistently investigations application and framework boundaries. This limits the requirement for human contribution. AD Automatic differentiation

Keywords- Cloud Native, Applications, Self-Adaptation, Adopting, Expansion. <span style="background-color: yellow;"><span style="background-color: yellow;"><span style="background-color: yellow;">(AD)</span> </span> </span>  Automatic differentiational

Introduction 

After an early era driven mostly by early adopters, most firms are now embracing cloud computing. New programs are being developed from the ground up to run in the cloud, while existing workloads are being updated and reworked more often to take advantage of cloud computing standards. The authors have already disseminated best practices for cloud application design in the papers presented at the 2015 Artificial Intelligence and Machine Learning Conference (AIMC'15). This article analyzes our non-practical behavior in regards to adaptability and toughness throughout the execution of the strategy we advocate using a particular mix of innovations. While there are several benefits to cloud computing, they may be broken down into two broad categories: practical (flexibility/speed) and conservative (costsCloud computing has many advantages, including self-service provisioning, task automation through application programming interfaces (APIs), instantaneous asset organisation and evacuation, accelerated provisioning of development, test, and production environments, and enhanced agility and time-to-showcase when dealing with business changes. More work is done as a consequence. Financially, the pay-as-you-go model eliminates the need for upfront capital to acquire or maintain IT assets; instead, businesses pay only for the resources they use. Additionally, by appointing the upkeep of actual IT framework, organizations might zero in on development as opposed to activities support and limit capital consumptions (capex) for use adjusted functional costs (opex) [1-3].

For models, see More out of control (2012), Fehling et al. (2014), and Homer et al. (2014) for broad arrangements of structural examples and best practices for creating cloud applications. Applications for putting away and handling information have been broadly taken on by the business because of the development of cloud processing throughout the course of recent years and its change into a help utility. The necessity for registering and stockpiling administrations is expected to increment later on years with the development of the IoT worldview , which will be joined by an expansion in how                information made at the organization's edge. Customary cloud administrations' brought together nature, which had been principally utilized for replication or business progression, is presently not legitimate. Cloud Administrations were previously provided as outsider computational assets, yet the deal has since extended concerning usefulness, setting, and innovation. After this alter, the way that clients consume these cloud administrations has likewise evolved. Rather than utilizing just a single kind of cloud administration from a solitary source, clients presently use an assortment of cloud administrations from at least one cloud suppliers. A multi-cloud methodology alludes to the successive or simultaneous usage of administrations from numerous suppliers to run an application. Cross breed Cloud is the expression frequently used to portray such a design worldview at the business level. It is "the planned use of cloud administrations across supplier and disengagement borders among public, private, and local area specialist co-ops, or among interior and outside cloud administrations," as indicated by Gartner [4-8].     

REVIEW OF LITREATURE

According to Yan, Zhenget, et al. (2011), cloud computing offers a replacement option for traditional service delivery and have grown to be a popular service platform. By storing user data in a cloud knowledge centre, user devices are considerably relieved of their storage load and access is made easier. Due to their mistrust of cloud service providers, customers typically save their sensitive data in an encrypted format. Nonetheless, in a number of situations, alternative businesses should have access to the information in order to provide an anticipated service, such as a health service. There are several application scenarios that call for flexible administration of cloud knowledge, access to supported knowledge owner policies, and application requirements. Each or the dependable third parties should be able to engage in this management in a flexible manner. Nonetheless, the current cloud computing models are effective and meet client demand. The usefulness of information exchange is trusted at every level in a risky setting. It aids in avoiding risks and overcoming ambiguity. Nevertheless, there is yet no logical solution in the literature for how to handle cloud knowledge access backed by name and trust. 33 Using attribute-based coding and proxy re-encryption, a theme is proposed in this work to govern knowledge access in cloud computing backed by trust evaluated by the information owner and/or names created by several reputation centres in a flexible way[9-12].

 The idea of context-aware trust and name analysis is frequently included into scientific systems in order to assist various management strategies and scenarios. By in-depth research, security proof, comparison, and implementation, the performance and safety of our theme were tested, evaluated, and even implemented. The outcomes demonstrate the strength, adaptability, and efficiency of our knowledge access management theme for cloud computing. According to Xie, Xiaolan, et al. (2014), a multi-agent and trust analysis assisted trust management model is presented. It establishes several third-party agents within the cloud, employs a centralised distribution management approach, and efficiently manages users and cloud services through the cooperation of the agents [13-16]. It will reduce the single-agent load of computation, storage, and user waiting time by utilising many third-party agents. The experiment demonstrates the utility of the trust management concept. In order to prevent users from accessing cloud knowledge at inappropriate times, 

Yue-Qin, Fan, et al. [2017] proposed a model that proposes a certain access control model supported role task in cloud computing. It will more effectively prevent unauthorised individuals from accessing cloud information. The concept of name price is presented, and specific thresholds are given, combining the advantages of the role access management model and, therefore, the task access management model. By evaluating the quantity of name price, it will regulate the user's interview times. It will increase users' ability to access historical records supported by the cloud and reduce the frequency of malicious user access to information in the cloud [17-21].

 Lastly, the experiment's findings demonstrate how much more suitable this access control is for dynamic access. According to Lin, Guoyua, and colleagues [2011], cloud computing will provide consumers with virtualized and ascendible net services, but it will also present significant security issues. One of the most important and crucial steps to ensure the security of cloud computing is access control. Nevertheless, directly implementing an antiquated access control approach in the cloud was unable to address the unpredictability and vulnerability brought on by cloud computing's open environment. Information security is frequently successfully warranted across interactions between users and hence the Cloud in a cloud computing environment, where only the safety and accountability of each interaction party are guaranteed. Hence, creating a trusting environment between users and the cloud platform is essential for implementing new access control techniques in the context of cloud computing.

EXPERIENCE

As part of the Cloud-Native Applications (CNA) research project at the Zurich Faculty of Applied Sciences18's Help Prototyping Lab, we developed and analysed a variety of CNA apps. Among the valuable results are CNA suggestions with the most predominant issues and mix-ups in cloud application advancement. Here, we examine our encounters executing the self-overseeing ideas talked about in the prior parts to a generally running application that utilizes a specific CNA support stack.

 

Implementation



Utilize case  <span style='background-color:#FF0000; color: white; display:table;'>&nbsp;distinguishing proof&nbsp;</span>  in sync one. Our investigations had two targets: first, to get down to earth mastery with the most current innovation empowering configuration designs for cloud-based applications; second, to really apply these examples to a regular business application that wasn't made to work on the cloud. We needed to exhibit that deterioration into more modest parts (even by part usefulness as opposed to application highlight) frequently empowers to accomplish strength and flexibility even in heritage applications, rather than beginning without any preparation with an application planned starting from the earliest stage for the cloud. BPTT Black propagation through time

We pursued the choice to regard the accompanying principles when it is suitable to decide if an application. The application ought to be: • open source, to guarantee that our tests can be reproduced; • "business," to energize the utilization of CNA procedures for inheritance applications; • of a typical kind, to create delegate results.

We invested some energy exploring various notable and very much inspected open source business applications, and we concocted a rundown of about 10 projects, including report the board frameworks, undertaking asset arranging, and client relationship the executives <span style="background-color: yellow;">(CRM)</span>  (DMS). There were only two choices staying after our assessment: SuiteCRM19 and Zurmo20.

We eventually decided to work with Zurmo. Zurmo was picked on the grounds that it was created by a group with broad CRM experience (beforehand giving a changed variant of SugarCRM at Intelestream), sticks to test-driven improvement <span style="background-color: yellow;">(TDD)</span>  standards, has a CRM's all's fundamental highlights without being excessively include weighty, and has a contemporary tasteful.

We are sure that the code is of good quality and that our progressions will not simply upset the framework in an unexpected or clandestine manner in view of the initial two variables. We regularly ran over claims that one of the greatest issues with CRMs is that people are not utilizing them appropriately while we were exploring them. use them. The last two contentions for picking Zurmo explicitly manage this issue. We accept Zurmo might be a CRM framework that its end customers would really use subsequent to surveying contending choices.



Fig.1. Zurmo initial architecture



Zurmo CRM is a PHP application built on top of the Yii web framework, and it makes use of Model-View-Controller architecture and a front-regulator to handle and process incoming HTTP requests (see Figure 6). It is recommended that you use Apache for your web server, MySQL for your database, and Memcached for your reservation needs. With an additional reserve layer, it is basically a standard solid 3-level application. Zurmo is best utilized related to Apache's PHP module. Subsequently, there is some close coupling between the rationale used to deal with HTTP demands and the genuine application rationale. COCO Common Objects in Context

Step 2: Stage is stage two. The following stage was choosing a stage to execute the application on. Both private and public cloud circumstances were something we needed to cover. We chose to utilize both our own confidential cloud and Amazon Web Administrations given that an OpenStack arrangement was accessible in our lab <span style="background-color: yellow;">(AWS)</span> .

We involved Fleet22 as an essential holder and wellbeing the executives part and CoreOS21 as a key VM picture. Along with a disseminated Etcd, Armada is a dispersed systemd (boot supervisor) bunch (key-esteem store). Subsequent to involving it for some time, we can unequivocally authenticate CoreOS's case that Armada is generally low-level and that different arrangements, like Kubernetes23, are more qualified for overseeing application-level holders. We didn't necessarily in every case have great encounters with the CoreOS + Armada stack, and we came into specific known imperfections that delivered the framework less solid than we had expected (for instance, erroneously pulling holders all the while from Docker hub24). Likewise, it very well may be trying to decide why a holder isn't booked for execution in Armada. Designers involving Armada interestingly would benefit significantly from more verbose order and logging yield.

Step 3: building modifications. Each part of the application must be adaptable and powerful. The principal thing we did was partition the program into its fundamental parts, (for example, the Apache Web server, Memcached, and MySQL RDBMS) and execute them in isolated Docker25 holders.

We decided to at first scale out the web server. Each Apache cycle has an implicit PHP mediator since the application center is in its unique design firmly associated with the web server. The application center scales naturally as the webserver does. Everything necessary to do this is a heap balancer that guides approaching HTTP solicitations to the web servers. Zurmo at first involved a nearby web server capacity strategy for meeting based information.

We changed the meeting taking care of with the end goal that the meeting state is presently saved both in the reserve and the data set. Presently, we can rapidly get it from the store, or on the other hand on the off chance that the reserve fizzles, we can in any case reestablish it from the data set. The design remains definitively a similar after this change, yet the program overall is currently versatile and vigorous. Following this change, determined meetings on Web servers are as of now excessive. To put it another way, We made the web server layer stateless so that users could be distributed uniformly across all active web servers and wouldn't be adversely affected if a web server or storage framework went down. CTC Connectionist Temporal Classification

By adding more servers to a group, Memcached's administration as of now upholds flat scaling. To CNA-ify extra parts of the framework, we next traded out the single server MySQL plan with a MySQL Galera Percona group.























Fig.2. Zurmo CNA Architecture

Step 4: is perception. We fostered a widespread observing arrangement that is effectively versatile to any CNA applications. The alleged ELK stack26, log-messenger, and collectd make up this framework. The ELK stack itself is comprised of Kibana, Logstash, and Elasticsearch. Log lines are accumulated by Logstash, which then binds together and conveys them to a foreordained result. Framework measurements are assembled by Collectd and saved in a document. The application and framework metric log documents from the holder in which a help is running are shipped off Logstash utilizing Log-Messenger. The result lines of Logstash are shipped off the full-text search administration Elasticsearch. Kibana is a logical device.







Fig.3. monitoring and logging



  EXPERIMENTAL RESULTS

We talk about our versatility and flexibility tests involving our cloud-native Zurmo execution in this part. In our github repository28, we offer the application's entire source code.

The tests we notice here were all sudden spike in demand for 12 t2.medium-sized virtual machines on Amazon AWS (eu-focal). The indistinguishable tests were likewise directed on our own Open Stack arrangement. The Open Stack discoveries are reliable with Amazon, subsequently we decide not to post them here since they contribute no new data. All things being equal, we decided to focus on the AWS preliminaries in light of a legitimate concern for working with confirmation and reproducibility. By introducing the Cloud Development format we give in the "aws" catalog of the execution, these can be immediately copied and freely checked.

The tests are intended to show that the recommended self-overseeing engineering and its model execution satisfactorily satisfy the flexibility and strength needs we framed for cloud-native applications. As such, we ask ourselves: Does the application scale (in and out) in light of burden varieties?

 Is the program shortcoming open minded? By ending the relating holders and virtual machines, we mimic IaaS disappointments to show versatility. An application's scaling is welcomed on by a heap generator whose force changes over the long haul.

We utilized a heap creation device by the name of Tsung29. By recording a Zurmo route circumstance by means of a program module, we had the option to later sum up and randomize it. This is additionally contained in the "zurmo tsung" part of our vault. The weight in our testing came from our PCs running Tsung locally. The quantity of clients that we reenacted consistently expanded (from 10 to 100), with a typical arbitrary idea season of 5 seconds between demands. With 100 simultaneous clients, this outcomes in a hypothetical greatest expected pace of 20 solicitations each second and a solicitation pace of 0.20 solicitations each second per client. North of 200 HTTP GET tasks and around 30 HTTP POST demands for data set reviews make most of the heap. It's imperative to take note of that each solicitation protecting information in the HTTP meeting object causes data set composes on the grounds that we decide not to use tacky HTTP meetings.



Scaling

We set Explosive to scale out the help and make another Apache compartment case each time the 95th percentile of the application reaction time (RT) reliably outperforms 1000 milliseconds in a 15-second stretch to answer the underlying question. All things being equal, any Apache holder whose central processor usage has been lower than 10% for something like 30 seconds will be closed somewhere around the scale in rationale.

We can stand to answer momentary signs (e.g., RT north of a couple of moments) since scaling all through holders is a genuinely fast activity. We likewise needed to keep up with our own virtual machines as we were involving Armada and CoreOS for the preliminaries as opposed to an IaaS administration that charged by the quantity of holders used. We used 10 VMs that weren't utilized for the scaling test and were pre-begun before the heap was started. The speculation is that engineers will just develop applications involving compartments later on, and that holder native applications might be charged for every holder's utilization right away. The Armada scheduler really dispenses compartments to virtual machines, which frequently delivers a predictable dissemination across all VMs. The application might scale on undeniable level execution pointers (like 95th percentiles) that are determined at ordinary stretches by the logstash part and saved to Etcd so We can get to them by utilizing our own interior observing framework.



Response time, request volume, user count, and the number of apache servers all function normally without externally induced issues

Experiment time (sec)	Response time (msec)	

2.3	2.9	

2.8	3.6	

3.2	3.8	

3.5	4.2	

4.2	4.9	

4.9	5.6	

5.2	6.2	



The logstash component calculates and stores in Etcd indisputable level execution markers (such as 95th percentiles) that we can access using our own internal monitoring system, suggesting that the application may grow based on these markers.

Table 1 portrays one occurrence of how the scaling motor dealt with a heap that began with 10 simultaneous clients and expanded to 100. The upper diagram shows the application reaction time (red nonstop line, left hub) in milliseconds and the solicitation rate (number of solicitations each second) (green ran line, right pivot).

At the point when the solicitation rate increments from around two solicitations each second to twenty, the reaction time is constrained by adaptively raising the quantity of Apache holders that are dynamic. The chart's base segment shows the all out number of Apache holders that are dynamic at any one second (shown by a red ceaseless line), along with the all out number of reenacted clients. The quantity of Apache holders is diminished at whatever point the delivered traffic stops.



Resilience to VM failures

Indeed, even without the mechanization models of MC-EMU or different projects like ChaosMonkey31, we imitated VM disappointments. All things being equal, we basically physically killed at least one VMs utilizing the Amazon dashboard at a specific chance to recognize pivotal periods.



Response time, request volume, user count, and the number of servers running Apache that cause probability container failure are all important metrics.

Experiment time (sec)	Request rate and mean response time	

                                               

1.2	2.2	

2.5	2.5	

2.9	3.9	

3.1	4.5	

3.9	4.8	

4.1	5.3	

5.3	6.2	



In our model methodology, the results of obliterating entire VMs differ essentially contingent upon the VM's capability in the Etcd group and the sort of holders it is running. As one would expect, closing down virtual machines that are just facilitating "stateless" (or practically stateless) compartments, like Apache and Memcached, just has minor and inconsistent effects on the application nature of administration. Ending a VM that is executing tasteful parts, like a data set, has impressively more clear effects.

There are 2 classifications of virtual machines (VMs) that we explicitly abstained from ending:

•	The logstash-running VM;

•	The virtual machines that are "individuals" of the Etcd bunch

CONCLUSION

In this article, we present our approach to designing with agreement techniques, cloud-based collaboration, and decentralized leadership, to permit cloud-based applications to self-make due. While numerous applications have viewed cloud figuring as an effective method for procuring calculation and capacity as a help, it will be unable to deal with the vast information created by IoT gadgets or enough help heterogeneous application necessities like those presented by multi-cloud applications. Applications that should stick to thorough ongoing reaction and low dormancy prerequisites or those supporting crucial frameworks are a portion of the applications that are especially impacted by a portion of the limitations of the conventional cloud model.

FUTURE SCOPE

The created a federation framework based on Cocuckoo based search to investigate the problem of a cost-based cloud alliance. It demonstrated how our model can be used in two different application scenarios, such as Energy Plus for energy optimisation and Octave for processing images of malignant growth, and it highlighted the benefits of an accumulated tuple-space (Comet space) for allocating resources based on a capacity for cost-based decision-making. Clients may post jobs and get results continuously in our Binary Cocuckoo-based search display, taking use of the advantages of outsourcing work. The demonstrated the organisation and use of the suggested technique and provisionally assessed various conditions for separate clouds and grouped mists. The results of the exploratory studies have demonstrated a number of advantages that league offers in terms of cost efficiency and errand completion.



REFERENCES

[1]  A Survey on IoT Related Security Issues, Challenges and Their Solutions." International Journal for Research in Engineering Application & Management, IJREAM Publishing House, Apr. 2020, pp. 378-83. Crossref, https://doi.org/10.35291/2454-9150.2020.0317

[2]  Adalberto Ribeiro Sampaio Jr et al. 2018. Improving Microservice-based Applications with Runtime Placement Adaptation. Journal of Internet Services and Applications (2018). 

[3]   Claus Pahl et al. 2017. Cloud container technologies: a state-of-the-art review. IEEE Transactions on Cloud Computing (2017). 

[4]    D. Weyns. 2017. Software Engineering of Self-Adaptive Systems: An Organised Tour and Future Challenges. Springer.

[5]  David Garlan, Robert T Monroe, and David Wile. 2000. Acme: Architectural description of component-based systems. Foundations of component-based systems 68 (2000), 47-68. 

[6]   E, Okereke. "A Machine Learning Based Framework for Predicting Student's Academic Performance." Physical Science & Biophysics Journal, vol. 4, no. 2, Medwin Publishers, 2020. Crossref, https://doi.org/10.23880/psbj-16000145

[7]   El-Gazzar RF (2014) A literature review on cloud computing adoption issues in enterprises. In: Bergvall-Kåreborn B, Nielsen PA (eds) Creating value for all through IT. Springer, Berlin Heidelberg, pp 214-242

[8]   Eric Brewer. 2018. Kubernetes and the New Cloud. In SIGMOD 2018. Invited Keynote.

[9]   S.Kannadhasan, M.Shanmuganantham and R.Nagarajan, System Model of VANET Using Optimization- Based Efficient Routing Algorithm, International Conference on Advances in Material Science, Communication and Microelectronics (ICAMCM-2021), Jaipur Engineering College and Research Centre, Jaipur, 19-20 February 2021. Published for IOP Conference Series: Materials Science and Engineering,  Vol No: 1119, 2021, doi:10.1088/1757-899X/1119/1/012021

 [10] Luca Florio and Elisabetta Di Nitto. 2016. Gru: An Approach to Introduce Decentralized Autonomic Behavior in Microservices architectures. In IEEE ICAC 2016. 357-362.D. Garlan et al. 2004. Rainbow: Architecture-Based Self-Adaptation with Reusable Infrastructure. Computer 37, 10 (2004), 46-54. 

[11] Maria A Rodriguez and Rajkumar Buyya. 2018. Containers Orchestration with Cost-E$cient Autoscaling in Cloud Computing Environments. arXiv preprint arXiv:1812.00300 (2018). 

[12] Nabor C Mendonça et al. 2018. Generality vs. Reusability in Architecture-Based Self-Adaptation: The Case for Self-Adaptive Microservices. In AKSAS 2018. 

[13] P. Jamshidi et al. 2018. Microservices: The Journey So Far and  Challenges Ahead. IEEE Software 35, 3 (2018), 24-35. 

[14]  Shang-Wen Cheng and David Garlan. 2012. Stitch: A language for architecturebased self-adaptation. Journal of Systems and Software 85, 12 (2012), 2860-2875. 

[15] S.Kannadhasan, M.Shanmuganantham, R.Nagarajan, and S.Deepa, Future Proofing Higher Education Challenges in Open and Distance Learning, International Virtual Conference on Immersive Education with VR/AR, VIT Vellore, 25 June 2020, Published for International Journal of Scientific Research and Engineering Development-- Volume 3 Issue 6, Nov-Dec 2020, ISSN : 2581-7175 jeeva

[16]	Karthick, A., Murugavel, K. K.,  Ghosh, A., Sudhakar, K., & Ramanan, P. (2020). Investigation of a binary eutectic mixture of phase change material for building integrated photovoltaic (BIPV) system. Solar Energy Materials and Solar Cells, 207, 110360.

[17]	Chandran, V., Patil, C. K., Karthick, A., Ganeshaperumal, D., Rahim, R., & Ghosh, A. (2021). State of charge estimation of lithium-ion battery for electric vehicles using machine learning algorithms. World Electric Vehicle Journal, 12(1), 38.

[18]	Karthick, A., Murugavel, K. K., & Ramanan, P. (2018). Performance enhancement of a building-integrated photovoltaic module using phase change material. Energy, 142, 803-812.

[19]	Maity, R., Sudhakar, K., Abdul Razak, A., Karthick, A., & Barbulescu, D. (2023). Agrivoltaic: A Strategic Assessment Using SWOT and TOWS Matrix. Energies, 16(8), 3313.

[20]	Sarkar, S., Karthick, A., Kumar Chinnaiyan, V., & Patil, P. P. (2023). Energy forecasting of the building-integrated photovoltaic façade using hybrid LSTM. Environmental Science and Pollution Research, 30(16), 45977-45985.

[21]	Jayalakshmi, N. Y., Shankar, R., Subramaniam, U., Baranilingesan, I., Karthick, A., Stalin, B., ... & Ghosh, A. (2021). Novel multi-time scale deep learning algorithm for solar irradiance forecasting. Energies, 14(9), 2404.









<h5>Conclusion</h5><h5>References</h5>
  </div><br/><br/>
  <div>
  
 
  <h3>Torture Phrases Word Counts:</h3>
  <ul>
  <div style='color: #FF0000; '>distinguishing proof: 1</div>
    </ul>
    </div>
    <br/>
    <h3>Self citation </h3>
    <ul></ul>
  <h3>Found in Abstract/Conclusion Section:</h3>
   <ul></ul></ul>
  <h3>Unmatched Abbreviations:</h3>
   <ul><div key=AD>
    AD - 3
  </div><div key=CRM>
    CRM - 1
  </div><div key=TDD>
    TDD - 1
  </div><div key=AWS>
    AWS - 1
  </div></ul><ul>
  </ul>
  
  </body></html>